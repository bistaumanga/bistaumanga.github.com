<!DOCTYPE html>
<html>
<head>
  <meta charset=utf-8>
  <meta name=viewport content="width=device-width, initial-scale=1.0">
  <meta name=description content="Personal website and blog of Umanga Bista">
  
  <title>
    
    Improving performance of Local outlier factor with KD-Trees | 
    
    Umanga Bista
  </title>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
  </script>
  
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  <link rel=stylesheet type=text/css href=/css/pure-min.css>
  <link rel=stylesheet type=text/css href=/css/github.css>
  <link rel=stylesheet type=text/css href=/css/styles.css>
  <link rel=stylesheet type=text/css href=/css/font-awesome/css/font-awesome.min.css>
</head>
<div id='menu'>
  <ul>
   <li><a href='/'>Home</a></li>
   <li><a href='/blog'>Blog</a></li>
   <li><a href='/publications'>Publications</a></li>
   <li><a href='/about'>Resume</a></li>
 </ul>
</div>
<body>
  <div class="container pure-g-r">
    <div class=pure-u-1-6>
      <div class=author-info>

    <img src="/images/author-image.jpg" class=author-image />
    <h1 class=author-name><a href=/>Umanga Bista</a></h1>
    <div class=nav>
        <a href="https://github.com/bistaumanga"><i class=icon-github-alt></i></a>
        <a href=""><i class=icon-twitter></i></a>
        <a href="https://np.linkedin.com/in/bistaumanga"><i class=icon-linkedin></a></i>
        <a href="https://www.researchgate.net/profile/Umanga_Bista"><i class=icon-bookmark-empty></i></a>
    </div>
    
    <p class=author-bio>Research Assistant at <a href=http://www.logpoint.com/>LogPoint</a>.<br>
Formerly, Computer Engineering undergrad at <a href=http://www.ioe.edu.np/>Institute of Engineering, Central Campus</a>.
</p>
    

    
</div>


    </div>
    <div class=pure-u-5-6>
      <div class=right-column>
        <div class=post>
    
    <ul class=post-meta>
    
        
    
    <li class=publish-time><i class=icon-calendar></i>April 21, 2014</li>
    
        <li>&middot;</li>
        <li><a href="/tags/#outlier,-ref">#outlier,</a></li>
    
        <li>&middot;</li>
        <li><a href="/tags/#local-ref">#local</a></li>
    
        <li>&middot;</li>
        <li><a href="/tags/#outlier,-ref">#outlier,</a></li>
    
        <li>&middot;</li>
        <li><a href="/tags/#kd-tree-ref">#kd-tree</a></li>
    
</ul>

    <h1 class=title-large>Improving performance of Local outlier factor with KD-Trees</h1>
    <div class=content>
        <p>Local outlier factor (LOF) is an outlier detection algorithm, that detects
outliers based on comparing local density of data instance with its neighbors.
It does so to decide if data instance belongs to region of similar density. It
can detect an outlier in a dataset, for which number of clusters is unknown, and
clusters are of different density and size. It's inspired from KNN (K-Nearest
Neighbors) algorithm, and is widely used. There is a <a href="http://www.rdatamining.com/examples/outlier-detection">R implemantation
available.</a></p>

<p>The naive approach to do this is to form all pair euclidan distance matrix, and
then run knn query to proceed further. But this approach just sucks, as it is
$\Theta(n^2)$ in terms of both space and time complexity. But, this can be
improvd with <a href="http://en.wikipedia.org/wiki/K-d_tree">KDTrees.</a>, and already its
<a href="http://scikit-learn.org/stable/modules/neighbors.html">implementation</a> exists
in python, thanks to scipy, so lets use this to find outliers.</p>

<h4 id="synthetic-dataset">Synthetic dataset</h4>

<div class="highlight"><pre><code class="python">    <span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c"># to reproduce the result</span>

    <span class="n">Populating</span> <span class="n">the</span> <span class="n">interactive</span> <span class="n">namespace</span> <span class="kn">from</span> <span class="nn">numpy</span> <span class="nn">and</span> <span class="nn">matplotlib</span>


    <span class="n">WARNING</span><span class="p">:</span> <span class="n">pylab</span> <span class="kn">import</span> <span class="nn">has</span> <span class="nn">clobbered</span> <span class="nn">these</span> <span class="nn">variables</span><span class="p">:</span> <span class="p">[</span><span class="s">&#39;dist&#39;</span><span class="p">]</span>
    <span class="sb">`%pylab --no-import-all`</span> <span class="n">prevents</span> <span class="n">importing</span> <span class="o">*</span> <span class="kn">from</span> <span class="nn">pylab</span> <span class="nn">and</span> <span class="nn">numpy</span>



    <span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span> <span class="c"># number of dimensions of dataset = 2</span>
    <span class="c"># cluster of normal random variable moderately dense</span>
    <span class="n">data1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1500</span><span class="p">],</span> <span class="p">[[</span><span class="mi">100000</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100000</span><span class="p">]],</span> <span class="mi">2000</span><span class="p">)</span>
    
    <span class="c"># very dense</span>
    <span class="n">data2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10000</span><span class="p">]],</span> <span class="mi">2500</span><span class="p">)</span>
    
    <span class="c"># sparse</span>
    <span class="n">data3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="mi">2500</span><span class="p">,</span> <span class="mi">2500</span><span class="p">],</span> <span class="p">[[</span><span class="mi">100000</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100000</span><span class="p">]],</span> <span class="mi">500</span><span class="p">)</span>
    
    <span class="c"># mix the three dataset and shuffle</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">)),</span> <span class="n">data3</span><span class="p">))</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
    <span class="c"># add some noise : zipf is skewed distribution and can have extreme values(outliers)</span>
    <span class="n">zipf_alpha</span> <span class="o">=</span> <span class="mf">2.25</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">zipf</span><span class="p">(</span><span class="n">zipf_alpha</span><span class="p">,</span> <span class="p">(</span><span class="mi">5000</span><span class="p">,</span><span class="n">dim</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="n">data</span> <span class="o">+=</span> <span class="n">noise</span>
    
</code></pre></div>

<h4 id="naive-approach-to-lof">Naive approach to LOF</h4>

<p>Pairwise Euclidean distance calculation with DistanceMetric implementation in
scikit-learn. In this, we just compute all-pair euclidean distance, i.e. $d(i,
j) = |x(i)-x(j)|_2$.</p>

<div class="highlight"><pre><code class="python">    <span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">DistanceMetric</span>
     <span class="c"># distance between points</span>
    <span class="kn">import</span> <span class="nn">time</span>
    <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">DistanceMetric</span><span class="o">.</span><span class="n">get_metric</span><span class="p">(</span><span class="s">&#39;euclidean&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">pairwise</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">&#39;++ took </span><span class="si">%g</span><span class="s"> msecs for Distance computation&#39;</span> <span class="o">%</span>  <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span><span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
    
</code></pre></div>

<div class="highlight"><pre><code class="python">    <span class="o">++</span> <span class="n">took</span> <span class="mi">740</span> <span class="n">msecs</span> <span class="k">for</span> <span class="n">Distance</span> <span class="n">computation</span>
    
</code></pre></div>

<p>Performing KNN query.In this step, the nearest k neighbors are identified
$N_k(i)$, and radius is the distance of k-th rearest neighbor of a datapoint.
<script type="math/tex"> r(i) = \max_{k \in N_k(i)} d(i, k) </script></p>

<div class="highlight"><pre><code class="python">    <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">k</span> <span class="o">=</span> <span class="mi">17</span> <span class="c"># number of neighbors to consider</span>
    <span class="c"># get the radius for each point in dataset (distance to kth nearest neighbor)</span>
    <span class="c"># radius is the distance of kth nearest point for each point in dataset        </span>
    <span class="n">idx_knn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span><span class="mi">1</span> <span class="p">:</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="c"># by row&#39; get k nearest neighbour   </span>
    <span class="n">radius</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="n">idx_knn</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="c"># radius</span>
    <span class="k">print</span> <span class="s">&#39;+++ took </span><span class="si">%g</span><span class="s"> msecs for KNN Querying&#39;</span> <span class="o">%</span>  <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span><span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
    
</code></pre></div>

<div class="highlight"><pre><code class="python">    <span class="o">+++</span> <span class="n">took</span> <span class="mi">4800</span> <span class="n">msecs</span> <span class="k">for</span> <span class="n">KNN</span> <span class="n">Querying</span>
    
</code></pre></div>

<p>Then LRD(Local Reachability distance) is calculated. For this, first reach
distance $rd(i, j)$ is computed between point concern $x(i)$ and its neighbors $
j:j\in N_k(i)$, which is the maximum of euclidean distance or radius $r(i)$ of
point concerned. Then, LRD is the inverse of mean of reach distance of all
k-neighbors of each point.
<script type="math/tex"> rd(i, j) = \max{\{d(i, j), r(i) }\} for\ j\in N_k(i) </script>
<script type="math/tex">LRD(i) = \frac{|N_k(i)|}{ \sum_{j \in N_k(i) }{rd(i, j)}} </script></p>

<div class="highlight"><pre><code class="python">    <span class="c"># calculate the local reachability density</span>
    <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">LRD</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">idx_knn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">LRD</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">dist</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">idx_knn</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">radius</span><span class="p">[</span><span class="n">idx_knn</span><span class="p">[</span><span class="n">i</span><span class="p">]])))</span>
    <span class="k">print</span> <span class="s">&#39;++++ took </span><span class="si">%g</span><span class="s"> msecs for LRD computation&#39;</span> <span class="o">%</span>  <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span><span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
    
</code></pre></div>

<div class="highlight"><pre><code class="python">    <span class="o">++++</span> <span class="n">took</span> <span class="mi">429</span> <span class="n">msecs</span> <span class="k">for</span> <span class="n">LRD</span> <span class="n">computation</span>
    
</code></pre></div>

<p>finally, the outlier score $LOF$ is calsulated.
<script type="math/tex"> LOF(i) = \frac { \sum_{j \in N_k(i)} {\frac{LRD(j)}{LRD(i)} }} { |N_k(i)|} </script></p>

<div class="highlight"><pre><code class="python">    <span class="c"># calculating the outlier score</span>
    <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">rho</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRD</span><span class="p">)</span> <span class="c"># inverse of density</span>
    <span class="n">outlier_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">rho</span><span class="p">[</span><span class="n">idx_knn</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
    <span class="n">outlier_score</span> <span class="o">*=</span> <span class="mf">1.</span><span class="o">/</span><span class="n">k</span>
    <span class="k">print</span> <span class="s">&#39;+++++ took </span><span class="si">%g</span><span class="s"> msecs for Outlier scoring&#39;</span> <span class="o">%</span>  <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span><span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
    
</code></pre></div>

<div class="highlight"><pre><code class="python">    <span class="o">+++++</span> <span class="n">took</span> <span class="mf">9.99999</span> <span class="n">msecs</span> <span class="k">for</span> <span class="n">Outlier</span> <span class="n">scoring</span>
    
</code></pre></div>

<p>Now lets se the histogram of Outlier score, to choose the optimal threshold to
decid weather a data-point is outlier is not.</p>

<div class="highlight"><pre><code class="python">    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">outlier_score</span><span class="p">)</span><span class="o">/</span><span class="n">outlier_score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c"># to normalize the histogram to probability plot</span>
    <span class="n">hist</span><span class="p">(</span><span class="n">outlier_score</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span> <span class="n">histtype</span> <span class="o">=</span> <span class="s">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#39;cyan&#39;</span><span class="p">)</span>
    <span class="n">title</span><span class="p">(</span><span class="s">&#39;Distribution of outlier score&#39;</span><span class="p">)</span>
    
</code></pre></div>

<div class="highlight"><pre><code class="python">    <span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">Text</span> <span class="n">at</span> <span class="mh">0x36030588</span><span class="o">&gt;</span>
    
</code></pre></div>

<p><img src="/images/lof_files/lof_16_1.png" alt="png" /></p>

<p>It can be observd that, the optimal outlier score threshold to decide weather a
data-point is outlier is outlier or not is around 2 for most of the cases, so
lets use it to see our sesults.</p>

<div class="highlight"><pre><code class="python">    <span class="n">threshold</span> <span class="o">=</span> <span class="mf">2.</span>
    <span class="c"># plot non outliers as green</span>
    <span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="s">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="c"># find the outliers and plot te outliers</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">outlier_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span>
    <span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="s">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    
</code></pre></div>

<div class="highlight"><pre><code class="python">    <span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">collections</span><span class="o">.</span><span class="n">PathCollection</span> <span class="n">at</span> <span class="mh">0x3640e6a0</span><span class="o">&gt;</span>
    
</code></pre></div>

<p><img src="/images/lof_files/lof_18_1.png" alt="png" /></p>

<p>We have seen the results of LOF with naive approachfor KNN queries. Now lets see
optimisations with KD-Trees.</p>

<h4 id="using-kd-trees">Using KD Trees</h4>

<p>KD-Trees insertion and KNN query.</p>

<div class="highlight"><pre><code class="python">    <span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KDTree</span> <span class="k">as</span> <span class="n">Tree</span>
    <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">BT</span> <span class="o">=</span> <span class="n">Tree</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="c"># Query for k nearest, k + 1 because one of the returnee is self</span>
    <span class="n">dx</span><span class="p">,</span> <span class="n">idx_knn</span> <span class="o">=</span> <span class="n">BT</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">print</span> <span class="s">&#39;++ took </span><span class="si">%g</span><span class="s"> msecs for Tree KNN Querying&#39;</span> <span class="o">%</span>  <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span><span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="o">++</span> <span class="n">took</span> <span class="mi">122</span> <span class="n">msecs</span> <span class="k">for</span> <span class="n">Tree</span> <span class="n">KNN</span> <span class="n">Querying</span>
    
</code></pre></div>

<p>LRD computation.</p>

<div class="highlight"><pre><code class="python">    <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">dx</span><span class="p">,</span> <span class="n">idx_knn</span> <span class="o">=</span> <span class="n">dx</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">idx_knn</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="c"># get the radius for each point in dataset</span>
    <span class="c"># radius is the distance of kth nearest point for each point in dataset        </span>
    <span class="n">radius</span> <span class="o">=</span> <span class="n">dx</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="c"># calculate the local reachability density</span>
    <span class="n">LRD</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">radius</span><span class="p">[</span><span class="n">idx_knn</span><span class="p">]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">print</span> <span class="s">&#39;++ took </span><span class="si">%g</span><span class="s"> msecs for LRD computation&#39;</span> <span class="o">%</span>  <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span><span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="o">++</span> <span class="n">took</span> <span class="mf">8.99982</span> <span class="n">msecs</span> <span class="k">for</span> <span class="n">LRD</span> <span class="n">computation</span>
    
</code></pre></div>

<p>Now, rest is same, so, i'm just replicating the rsult for completion.</p>

<div class="highlight"><pre><code class="python">    <span class="c"># calculating the outlier score</span>
    <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">rho</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRD</span><span class="p">)</span> <span class="c"># inverse of density</span>
    <span class="n">outlier_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">rho</span><span class="p">[</span><span class="n">idx_knn</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
    <span class="n">outlier_score</span> <span class="o">*=</span> <span class="mf">1.</span><span class="o">/</span><span class="n">k</span>
    <span class="k">print</span> <span class="s">&#39;+++++ took </span><span class="si">%g</span><span class="s"> msecs for Outlier scoring&#39;</span> <span class="o">%</span>  <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span><span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
    
    <span class="c"># plotiing the histogram of outlier score</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">outlier_score</span><span class="p">)</span><span class="o">/</span><span class="n">outlier_score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c"># to normalize the histogram to probability plot</span>
    <span class="n">hist</span><span class="p">(</span><span class="n">outlier_score</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span> <span class="n">histtype</span> <span class="o">=</span> <span class="s">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#39;cyan&#39;</span><span class="p">)</span>
    <span class="n">title</span><span class="p">(</span><span class="s">&#39;Distribution of outlier score&#39;</span><span class="p">)</span>
    
    <span class="c">#plotting the result</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="mf">2.</span>
    <span class="c"># plot non outliers as green</span>
    <span class="n">figure</span><span class="p">()</span>
    <span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="s">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="c"># find the outliers and plot te outliers</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">outlier_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span>
    <span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="s">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="o">+++++</span> <span class="n">took</span> <span class="mf">4.00019</span> <span class="n">msecs</span> <span class="k">for</span> <span class="n">Outlier</span> <span class="n">scoring</span>

    <span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">collections</span><span class="o">.</span><span class="n">PathCollection</span> <span class="n">at</span> <span class="mh">0x36ad0b38</span><span class="o">&gt;</span>
    
</code></pre></div>

<p><img src="/images/lof_files/lof_26_2.png" alt="png" /></p>

<p><img src="/images/lof_files/lof_26_3.png" alt="png" /></p>

<p>The results are same, and should be.</p>

<h4 id="putting-everything-together">Putting everything together</h4>

<p>Lets create a class, to combine evrything together. It will be important in
evaluating performance. From above results, we note that the most time is spent
for KNN querying.</p>

<div class="highlight"><pre><code class="python">    <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
    <span class="kn">import</span> <span class="nn">sys</span>
    <span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">DistanceMetric</span>
    <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
    <span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KDTree</span> <span class="k">as</span> <span class="n">Tree</span>
    
    <span class="k">def</span> <span class="nf">exit</span><span class="p">():</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
    
    <span class="k">class</span> <span class="nc">LOF</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        
        <span class="c"># a function to create synthetic test data</span>
        <span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
            
            <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="mi">5</span>
            <span class="n">n3</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="n">n1</span> <span class="o">-</span> <span class="n">n2</span>
            
            <span class="c"># cluster of gaussian random data</span>
            <span class="n">data1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
            
            <span class="c"># cluster of uniform random variable</span>
            <span class="n">data2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">n2</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
            
            <span class="c"># cluster of dense uniform random variable</span>
            <span class="n">data3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">n3</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
            
            <span class="c"># mix the three dataset</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">)),</span> <span class="n">data3</span><span class="p">))</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            
            <span class="c"># add some noise : zipf is skewed distribution</span>
            <span class="n">zipf_alpha</span> <span class="o">=</span> <span class="mf">2.5</span>
            <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">zipf</span><span class="p">(</span><span class="n">zipf_alpha</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dim</span><span class="p">))</span> <span class="o">*</span> \
                                <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">noise</span>
        
        <span class="c"># KNN querying with naive approach</span>
        <span class="k">def</span> <span class="nf">_knn_naive</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    
            <span class="c"># distance between points</span>
            <span class="c"># import time</span>
            <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">DistanceMetric</span><span class="o">.</span><span class="n">get_metric</span><span class="p">(</span><span class="s">&#39;euclidean&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">pairwise</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="c"># print &#39;++ took %g msecs for Distance computation&#39; %  ((time.time() - tic)* 1000)</span>
            <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="c"># get the radius for each point in dataset (distance to kth nearest neighbor)</span>
            <span class="c"># radius is the distance of kth nearest point for each point in dataset        </span>
            <span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span><span class="mi">1</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="c"># by row&#39; get k nearest neighbour   </span>
            <span class="n">radius</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="c"># radius</span>
            <span class="c"># print &#39;+++ took %g msecs for KNN Querying&#39; %  ((time.time() - tic)* 1000)</span>
            <span class="c"># calculate the local reachability density</span>
            <span class="n">LRD</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">LRD</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">dist</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">radius</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span><span class="p">[</span><span class="n">i</span><span class="p">]])))</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRD</span><span class="p">)</span>
            
        <span class="c"># knn querying with KDTrees</span>
        <span class="k">def</span> <span class="nf">_knn_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
            <span class="c">#import time</span>
            <span class="c"># tic = time.time()</span>
            <span class="n">BT</span> <span class="o">=</span> <span class="n">Tree</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c"># Query for k nearest, k + 1 because one of the returnee is self</span>
            <span class="n">dx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span> <span class="o">=</span> <span class="n">BT</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:],</span> <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
            <span class="c"># print &#39;++ took %g msecs for Tree KNN Querying&#39; %  ((time.time() - tic)* 1000)</span>
            
            <span class="n">dx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span> <span class="o">=</span> <span class="n">dx</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
            <span class="c"># get the radius for each point in dataset</span>
            <span class="c"># radius is the distance of kth nearest point for each point in dataset        </span>
            <span class="n">radius</span> <span class="o">=</span> <span class="n">dx</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="c"># calculate the local reachability density</span>
            <span class="n">LRD</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">radius</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span><span class="p">]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">LRD</span>
    
        <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s">&#39;Naive&#39;</span><span class="p">)</span> <span class="p">:</span>
            
            <span class="c"># check if dataset is provided for training</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">data</span> <span class="o">!=</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
                <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c"># number of data points</span>
                
            <span class="k">except</span> <span class="ne">AssertionError</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c"># number of data points</span>
                <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&#39;No data to fit the model, please provide data or call generate_data method&#39;</span>
                    <span class="nb">exit</span><span class="p">()</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;naive&#39;</span><span class="p">,</span> <span class="s">&#39;n&#39;</span><span class="p">,</span> <span class="s">&#39;tree&#39;</span><span class="p">,</span> <span class="s">&#39;t&#39;</span><span class="p">]</span>
            <span class="k">except</span> <span class="ne">AssertionError</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&#39;Method must be Naive|n or tree|t&#39;</span>
                <span class="nb">exit</span><span class="p">()</span>
           
            <span class="c"># find the rho, which is inverse of  LRD</span>
            <span class="k">if</span> <span class="n">method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;naive&#39;</span><span class="p">,</span> <span class="s">&#39;n&#39;</span><span class="p">]:</span>
                <span class="n">rho</span> <span class="o">=</span> <span class="mf">1.</span><span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_knn_naive</span><span class="p">()</span>
            
            <span class="k">elif</span> <span class="n">method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;tree&#39;</span><span class="p">,</span> <span class="s">&#39;t&#39;</span><span class="p">]:</span>
                <span class="n">rho</span> <span class="o">=</span> <span class="mf">1.</span><span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_knn_tree</span><span class="p">()</span>
    
            <span class="bp">self</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">rho</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_knn</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">score</span> <span class="o">*=</span> <span class="mf">1.</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span>
            
        <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
            
            <span class="c"># set the threshold</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">threshold</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">scipy.stats.mstats</span> <span class="kn">import</span> <span class="n">mquantiles</span>
                <span class="n">threshold</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">mquantiles</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">),</span> <span class="mf">2.</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
            <span class="c"># reduce data to 2D if required</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
                <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                
            <span class="c"># plot non outliers as green</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="s">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
            
            <span class="c"># find the outliers and plot te outliers</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="s">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s">&#39;Normal&#39;</span><span class="p">,</span> <span class="s">&#39;Outliers&#39;</span><span class="p">])</span>
            
            <span class="c"># plot the distribution of outlier score</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span> <span class="n">histtype</span> <span class="o">=</span> <span class="s">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#39;cyan&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Distribution of outlier score&#39;</span><span class="p">)</span>
    
</code></pre></div>

<h4 id="performance-evaluation">Performance Evaluation</h4>

<p>Lets create a function to evaluate te performance.</p>

<div class="highlight"><pre><code class="python">    <span class="k">def</span> <span class="nf">perf_test</span><span class="p">(</span><span class="n">n_list</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;Tree&#39;</span><span class="p">,</span> <span class="s">&#39;Naive&#39;</span><span class="p">],</span> <span class="n">plot</span> <span class="o">=</span> <span class="bp">False</span><span class="p">):</span>
        
        <span class="kn">import</span> <span class="nn">time</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">n_list</span><span class="p">:</span> <span class="n">n_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">14</span><span class="p">)]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">n_list</span><span class="p">:</span>
                <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">lof</span> <span class="o">=</span> <span class="n">LOF</span><span class="p">(</span><span class="n">k</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
                <span class="n">lof</span><span class="o">.</span><span class="n">generate_data</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">lof</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="n">m</span><span class="p">)</span>
                <span class="n">temp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1000000</span> <span class="o">*</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">tic</span><span class="p">))</span>
                <span class="k">print</span> <span class="s">&#39;Took </span><span class="si">%g</span><span class="s"> msecs with </span><span class="si">%s</span><span class="s"> method for </span><span class="si">%d</span><span class="s"> datapoints&#39;</span> <span class="o">%</span> \
                    <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">plot</span><span class="p">:</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s">&#39;log&#39;</span><span class="p">,</span> <span class="n">basex</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s">&#39;log&#39;</span><span class="p">,</span> <span class="n">basey</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;m*-&#39;</span><span class="p">,</span> <span class="n">ms</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">mec</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">try</span> <span class="p">:</span>    
                <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">result</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s">&#39;co--&#39;</span><span class="p">,</span> <span class="n">ms</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">mec</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;Number of data points $n$&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;Time of execution $\mu secs$&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">methods</span><span class="p">,</span> <span class="s">&#39;upper left&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
</code></pre></div>

<p>Now, lets compare the performace of 2 methods- Naive and KDTree implementations.</p>

<div class="highlight"><pre><code class="python">    <span class="n">perf_test</span><span class="p">(</span><span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;Tree&#39;</span><span class="p">,</span> <span class="s">&#39;Naive&#39;</span><span class="p">],</span> <span class="n">n_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">14</span><span class="p">)],</span> <span class="n">plot</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

    <span class="n">Took</span> <span class="mf">2.00009</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">16</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">1.99986</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">32</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">2.00009</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">64</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">3.00002</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">128</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">4.99988</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">256</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">11.0002</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">512</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">20.9999</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">1024</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">48.0001</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">2048</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">106</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">4096</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">179</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">8192</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">3.00002</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">16</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">3.00002</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">32</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">6.00004</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">64</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">13</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">128</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">30.9999</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">256</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">82.9999</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">512</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">249</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">1024</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">834</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">2048</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">3734</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">4096</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">15796</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Naive</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">8192</span> <span class="n">datapoints</span>
    
</code></pre></div>

<p><img src="/images/lof_files/lof_35_1.png" alt="png" /></p>

<p>We see that KDTree outperforms Naive method for narge $n$, but it may not do
well for small number of datasets. In my PC, i cannot run Naive method beyond
$2^{13}$ datapoints, or else i receie MemoryError. So, lets evauate te
performance of KDTrees upto 1Million datapoints.</p>

<div class="highlight"><pre><code class="python">    <span class="n">perf_test</span><span class="p">(</span><span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;Tree&#39;</span><span class="p">],</span> <span class="n">n_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">21</span><span class="p">)],</span> <span class="n">plot</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

    <span class="n">Took</span> <span class="mf">2.00009</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">16</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">2.00009</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">32</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">1.99986</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">64</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">3.00002</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">128</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">6.00004</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">256</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mf">9.00006</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">512</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">20</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">1024</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">50</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">2048</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">108</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">4096</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">194</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">8192</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">396</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">16384</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">837</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">32768</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">1741</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">65536</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">3596</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">131072</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">7824</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">262144</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">18207</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">524288</span> <span class="n">datapoints</span>
    <span class="n">Took</span> <span class="mi">40017</span> <span class="n">msecs</span> <span class="k">with</span> <span class="n">Tree</span> <span class="n">method</span> <span class="k">for</span> <span class="mi">1048576</span> <span class="n">datapoints</span>
    
</code></pre></div>

<p><img src="/images/lof_files/lof_37_1.png" alt="png" /></p>

<p>We can see, algorithm is scaling well with data-set size $n$. If we analyse the
complexity of algorithm, its linearithmin , i.e. $\Theta (n\log{n})$.</p>

<h4 id="download-this-post-as">Download this post as:</h4>
<p><a href="/files/lof.ipynb">Ipython Notebook</a> | <a href="/files/lof.pdf">PDF</a></p>

        <p class=discuss>
            Discuss this post via <a href="mailto:bistaumanga@gmail.com">e-mail</a>
        </p>
    </div>

    
    <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'bistaumanga'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        
        

    </div>

      </div>
    </div>
  </div>
  <script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'bistaumanga'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
      var s = document.createElement('script'); s.async = true;
      s.type = 'text/javascript';
      s.src = '//' + disqus_shortname + '.disqus.com/count.js';
      (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
    </script>
  </body>
  </html>
